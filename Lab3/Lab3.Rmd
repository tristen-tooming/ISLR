---
title: "Lab3"
author: "Tristen Tooming"
date: "2/3/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


###Assignment 1: Analysis of mortality rates using splines

##### Pre
```{r}
mortality_rate = read.csv('mortality_rate.csv', header = TRUE, sep = ';')
summary(mortality_rate$Rate)
```

##### 1.a.

```{r}
mortality_rate$lmr = log(mortality_rate$Rate)
plot(mortality_rate$Day, mortality_rate$lmr,
     ylab = 'LMR',
     xlab = 'Day',
     main = 'Log-Mortality-Rate (LMR)')
```
<br>
> Plot looks a little bit scrappy and you cannot see a solid 'line' to indicate that data follows an exponential mortality rate. 

###### 1.b

```{r}
library(splines)

fit_ns_1 = lm(lmr ~ ns(Day, df = 2), data = mortality_rate)
pred1 = predict(fit_ns_1, newdata = list(Day=mortality_rate$Day))

fit_ns_2 = lm(lmr ~ ns(Day, df = 3), data = mortality_rate)
pred2 = predict(fit_ns_2, newdata = list(Day=mortality_rate$Day))

fit_ns_3 = lm(lmr ~ ns(Day, df = 16), data = mortality_rate)
pred3 = predict(fit_ns_3, newdata = list(Day=mortality_rate$Day))

fit_ns_4 = lm(lmr ~ ns(Day, df = 51), data = mortality_rate)
pred4 = predict(fit_ns_4, newdata = list(Day=mortality_rate$Day))
```


```{r, echo=F}
plot(mortality_rate$Day, mortality_rate$lmr, xlab = 'Day', ylab = 'LMR',
     main = 'Natural cubic splies fit #1 (knots = 1)')
lines(mortality_rate$Day, pred1, col='black', lwd = 2)
points(attr(ns(mortality_rate$Day, df = 2), "knots"),
  predict(fit_ns_1,
          data.frame(Day = attr(ns(mortality_rate$Day, df = 2), "knots"))),
  col="black",pch=4, lwd = 3, cex = 1)

plot(mortality_rate$Day, mortality_rate$lmr, xlab = 'Day', ylab = 'LMR',
     main = 'Natural cubic splies fit #2 (knots = 2)')
lines(mortality_rate$Day, pred2, col='blue', lwd = 2)
points(attr(ns(mortality_rate$Day, df = 3), "knots"),
  predict(fit_ns_2,
          data.frame(Day = attr(ns(mortality_rate$Day, df = 3), "knots"))),
  col="blue",pch=4, lwd = 3, cex = 1)

plot(mortality_rate$Day, mortality_rate$lmr, xlab = 'Day', ylab = 'LMR',
     main = 'Natural cubic splies fit #3 (knots = 15)')
lines(mortality_rate$Day, pred3, col='green', lwd = 2)
points(attr(ns(mortality_rate$Day, df = 16), "knots"),
  predict(fit_ns_2,
          data.frame(Day = attr(ns(mortality_rate$Day, df = 16), "knots"))),
  col="green",pch=4, lwd = 3, cex = 1)

plot(mortality_rate$Day, mortality_rate$lmr, xlab = 'Day', ylab = 'LMR',
     main = 'Natural cubic splies fit #4 (knots = 50)')
lines(mortality_rate$Day, pred4, col='red', lwd = 2)
points(attr(ns(mortality_rate$Day, df = 51), "knots"),
  predict(fit_ns_2,
          data.frame(Day = attr(ns(mortality_rate$Day, df = 51), "knots"))),
  col="red",pch=4, lwd = 3, cex = 1)


for (i in 1:4) {
  cat(sprintf("Model #%s MSE: %.2f \n", i,
              mean(eval(as.name(paste(c('fit_ns_', i), collapse = '')))$residuals^2)))  
}
```
<br>> Based on MSE model number four performs best. However with that many knots it can lead to overfit of the model. Model number three or even number two could be better choices. Needs more testing/validation.

##### 1.c
```{r, warning=F}

# Calc MSE
calc_mse = function(actual, pred) {
  return(mean((actual - pred) ** 2))
}



test = function(data, nknots) {
  mse_data = data.frame(matrix(nrow = 0, ncol = 4))
  
  # Column names based on the knots
  cnames = c()
  cnames_mse = c()
  for (x in 1:length(nknots)) {
    cnames[x] = paste(c('nkonts_', nknots[x]), collapse ='')
    cnames_mse[x]= paste(c('MSE_of_nkonts_', nknots[x]), collapse ='')
  }
  colnames(mse_data) = cnames
  
  
  # Fitting and data splitting
  for (i in 1:10) {
    set.seed(2707 + i)
    smp_size <- floor(0.7 * nrow(data))
    train_ind <- sample(seq_len(nrow(data)), size = smp_size)

    train <- data[train_ind, ]
    test <- data[-train_ind, ]

    for (j in 1:length(nknots)) {
      fit = lm(lmr ~ ns(Day, df = nknots[j] + 1), data = train)
      pred_lmr = predict(fit, newdata=list(Day=test$Day))
      
      # Warning: prediction from a rank-deficient fit may be misleading
      
      # A matrix that does not have "full rank" is said to be "rank deficient".
      # A matrix is said to have full rank if its rank is either equal to its
      # number of columns or to its number of rows (or to both).
      mse_data[i, j] = calc_mse(test$lmr, pred_lmr)
    }
  }

  
  # Return data
  return_data = vector(mode="list", length=5)
  
  names(return_data) = c('MSE_data', cnames_mse)
  
  return_data$MSE_data = mse_data
  for (c in 1:ncol(mse_data)) {
    return_data[c + 1] = mean(mse_data[, c])
  }
  
  return(return_data)
}


print(test(mortality_rate, nknots=c(1, 2, 15, 50)))

```
<br>
> Compared to 1 b MSEs are considerably higher. With this seed best MSE (1.56) is from model with fifthteen knots. Model with fifty knots gives absurd MSE.

##### 1.d. 

```{r}
fit_smooth <- smooth.spline(x=mortality_rate$Day, y=mortality_rate$lmr, cv = T)
pred_lmr = predict(fit_smooth, newdata=mortality_rate)$y
MSE=mean((mortality_rate$lmr-pred_lmr)^2)

cat(sprintf('MSE: %.2g \n', MSE))
cat(sprintf('Lambda: %.2g \n', fit_smooth$lambda))  #Smoothing parameter
cat(sprintf('Number of Knots: %s \n', fit_smooth$fit$nk))
cat(sprintf('Avarage of the effective Degrees of Freedom: %.3g \n', fit_smooth$df - 2))
```
<br>
> Smoothing splines performs effectively comprored to natural cubic splines with MSE of 0.081 and difference to best cubic models MSE is (0.119 - 0.081) 0.038.


### Assignment 2: Comparison of GAMs with spline and loess basis functions

##### Pre

```{r}
auto_mpg = read.table('auto-mpg.txt', header = T)

auto_mpg$year = factor(auto_mpg$year)
auto_mpg$origin = factor(auto_mpg$origin)

auto_mpg = auto_mpg[ , !(names(auto_mpg) %in% 'name')]

summary(auto_mpg)
```

```{r, cache=TRUE}
# 2.a. Set up a lasso model (option ‘glmnet’) for all data with the train()
# function in the caret and use LOOCV to find the RMSE.
# In order to tune the alpha and lambda parameters, set the tuneLength = 50.
# Present the best model (not all) and its model fit criteria.

library(caret)

tuneGrid <- expand.grid(alpha = 1, lambda = seq(0.0001, 1, length = 50))

fit_lasso = train(mpg ~.,
                  data = auto_mpg,
                  method = "glmnet",
                  tuneGrid = tuneGrid,
                  tuneLength = 50,
                  trControl = trainControl("LOOCV", number = 1))
```
```{r}
#str(fit_lasso)
#getTrainPerf(fit_lasso)[1]

RMSE = fit_lasso$results$RMSE

cat(sprintf('Lasso best Model RMSE: %.4g', RMSE[which.min(RMSE)]))
```


```{r, cache=TRUE}
# 2.b. Set up a GAM model with spline basis functions for all data
# with the train() function in the caret package and use LOOCV to find the best RMSE.
# Find a reasonable interval for the tuning parameter df. Present the table
# of the evaluated models and their model fit criteria.

library(gam)
# Build the GAM model based on splines and find best model with LOOCV
fit_gam_spline <- train(
  mpg~., data = auto_mpg, method = "gamSpline",
  scale = FALSE,
  trControl = trainControl("LOOCV", number = 1),
  tuneGrid = expand.grid(df = seq(1, 9, length = 9)))
```
```{r}
fit_gam_spline
#summary(fit_gam_spline$finalModel)
cat(sprintf('GAM Split best model RMSE: %.4g', min(fit_gam_spline$results$RMSE)))
```


##### 2.c
```{r, warning=F, cache=TRUE}
# 2.c. Set up a GAM model with loess basis functions for all data with the train()
# function in the caret package and use LOOCV to find the RMSE. Find a reasonable
# interval for the tuning parameter span and fix degree to 1.
# Present the table of the evaluated models and their model fit criteria.

# Build the GAM model based on splines and find best model with LOOCV
fit_gam_loess <- train(
  mpg~., data = auto_mpg, method = "gamLoess",
  scale = FALSE,
  trControl = trainControl("LOOCV", number = 1),
  tuneGrid = expand.grid(span = seq(0.1, 0.5, length = 9),
                         degree = c(rep(1,9))))
```
```{r}
fit_gam_loess
cat(sprintf('GAM Loess best model RMSE: %.4g', min(fit_gam_loess$results$RMSE)))
```


##### 2.d. Best Model

```{r, results='hold'}
# Present a plot of the regression coefficient/curves for the method that performed best.

# Best model is Generalized Additive Model using Splines 

par(mfrow = c(3,4))
plot(fit_gam_spline$finalModel)

```


